{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1e12e6f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-05T23:12:04.471126Z",
     "iopub.status.busy": "2023-09-05T23:12:04.470483Z",
     "iopub.status.idle": "2023-09-05T23:12:04.482200Z",
     "shell.execute_reply": "2023-09-05T23:12:04.481020Z"
    },
    "papermill": {
     "duration": 0.024349,
     "end_time": "2023-09-05T23:12:04.484551",
     "exception": false,
     "start_time": "2023-09-05T23:12:04.460202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/spaceship-titanic/sample_submission.csv\n",
      "/kaggle/input/spaceship-titanic/train.csv\n",
      "/kaggle/input/spaceship-titanic/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec1acc57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T23:12:04.499584Z",
     "iopub.status.busy": "2023-09-05T23:12:04.499154Z",
     "iopub.status.idle": "2023-09-05T23:12:14.569014Z",
     "shell.execute_reply": "2023-09-05T23:12:14.567673Z"
    },
    "papermill": {
     "duration": 10.080198,
     "end_time": "2023-09-05T23:12:14.571569",
     "exception": false,
     "start_time": "2023-09-05T23:12:04.491371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_decision_forests as tfdf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9a5e763",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T23:12:14.586831Z",
     "iopub.status.busy": "2023-09-05T23:12:14.585675Z",
     "iopub.status.idle": "2023-09-05T23:12:14.706914Z",
     "shell.execute_reply": "2023-09-05T23:12:14.705677Z"
    },
    "papermill": {
     "duration": 0.131054,
     "end_time": "2023-09-05T23:12:14.709266",
     "exception": false,
     "start_time": "2023-09-05T23:12:14.578212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full train dataset shape is (8693, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HomePlanet      0\n",
       "CryoSleep       0\n",
       "Destination     0\n",
       "Age             0\n",
       "VIP             0\n",
       "RoomService     0\n",
       "FoodCourt       0\n",
       "ShoppingMall    0\n",
       "Spa             0\n",
       "VRDeck          0\n",
       "Transported     0\n",
       "Deck            0\n",
       "Cabin_num       0\n",
       "Side            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a dataset into a Pandas Dataframe\n",
    "dataset_df = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')\n",
    "print(\"Full train dataset shape is {}\".format(dataset_df.shape))\n",
    "\n",
    "dataset_df = dataset_df.drop(['PassengerId', 'Name'], axis=1)\n",
    "dataset_df[[\"Deck\", \"Cabin_num\", \"Side\"]] = dataset_df[\"Cabin\"].str.split(\"/\", expand=True)\n",
    "dataset_df = dataset_df.drop('Cabin', axis=1)\n",
    "dataset_df.fillna(0, inplace=True)\n",
    "dataset_df['Transported'] = dataset_df['Transported'].astype(int)\n",
    "dataset_df['VIP'] = dataset_df['VIP'].astype(int)\n",
    "dataset_df['CryoSleep'] = dataset_df['CryoSleep'].astype(int)\n",
    "dataset_df.head(5)\n",
    "dataset_df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ba4eb06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T23:12:14.724800Z",
     "iopub.status.busy": "2023-09-05T23:12:14.724404Z",
     "iopub.status.idle": "2023-09-05T23:12:14.734106Z",
     "shell.execute_reply": "2023-09-05T23:12:14.733152Z"
    },
    "papermill": {
     "duration": 0.019757,
     "end_time": "2023-09-05T23:12:14.736103",
     "exception": false,
     "start_time": "2023-09-05T23:12:14.716346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6987 examples in training, 1706 examples in testing.\n"
     ]
    }
   ],
   "source": [
    "def split_dataset(dataset, test_ratio=0.20):\n",
    "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "  return dataset[~test_indices], dataset[test_indices]\n",
    "\n",
    "train_ds_pd, valid_ds_pd = split_dataset(dataset_df)\n",
    "print(\"{} examples in training, {} examples in testing.\".format(\n",
    "    len(train_ds_pd), len(valid_ds_pd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4ff0a90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T23:12:14.752095Z",
     "iopub.status.busy": "2023-09-05T23:12:14.751547Z",
     "iopub.status.idle": "2023-09-05T23:12:14.757789Z",
     "shell.execute_reply": "2023-09-05T23:12:14.756773Z"
    },
    "papermill": {
     "duration": 0.017101,
     "end_time": "2023-09-05T23:12:14.760135",
     "exception": false,
     "start_time": "2023-09-05T23:12:14.743034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_columns(dataframe, target=None, features=None):\n",
    "    for name in dataframe.columns.values:\n",
    "        if name != target:\n",
    "            if is_numeric_dtype(dataframe[name]):\n",
    "                dataframe[name] = dataframe[name].astype('float')\n",
    "                if features != None:\n",
    "                    feature_columns.append(tf.feature_column.numeric_column(name))\n",
    "            else:\n",
    "                dataframe[name] = dataframe[name].astype('string')\n",
    "                dataframe[name] = dataframe[name].astype('category')\n",
    "                if features != None:\n",
    "                    features.append(tf.feature_column.embedding_column(tf.feature_column.categorical_column_with_vocabulary_list(name, vocabulary_list=dataframe[name].unique()), dimension=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ead6fb1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T23:12:14.775748Z",
     "iopub.status.busy": "2023-09-05T23:12:14.775386Z",
     "iopub.status.idle": "2023-09-05T23:12:14.825884Z",
     "shell.execute_reply": "2023-09-05T23:12:14.824294Z"
    },
    "papermill": {
     "duration": 0.061107,
     "end_time": "2023-09-05T23:12:14.828243",
     "exception": false,
     "start_time": "2023-09-05T23:12:14.767136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20/3352524088.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('string')\n",
      "/tmp/ipykernel_20/3352524088.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('category')\n",
      "/tmp/ipykernel_20/3352524088.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('float')\n",
      "/tmp/ipykernel_20/3352524088.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('string')\n",
      "/tmp/ipykernel_20/3352524088.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('category')\n",
      "/tmp/ipykernel_20/3352524088.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('float')\n",
      "/tmp/ipykernel_20/3352524088.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('string')\n",
      "/tmp/ipykernel_20/3352524088.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('category')\n",
      "/tmp/ipykernel_20/3352524088.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('string')\n",
      "/tmp/ipykernel_20/3352524088.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('category')\n",
      "/tmp/ipykernel_20/3352524088.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('string')\n",
      "/tmp/ipykernel_20/3352524088.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('category')\n",
      "/tmp/ipykernel_20/3352524088.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('string')\n",
      "/tmp/ipykernel_20/3352524088.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('category')\n",
      "/tmp/ipykernel_20/3352524088.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('float')\n",
      "/tmp/ipykernel_20/3352524088.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('string')\n",
      "/tmp/ipykernel_20/3352524088.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('category')\n",
      "/tmp/ipykernel_20/3352524088.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('float')\n",
      "/tmp/ipykernel_20/3352524088.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('string')\n",
      "/tmp/ipykernel_20/3352524088.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('category')\n",
      "/tmp/ipykernel_20/3352524088.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('string')\n",
      "/tmp/ipykernel_20/3352524088.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('category')\n",
      "/tmp/ipykernel_20/3352524088.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('string')\n",
      "/tmp/ipykernel_20/3352524088.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[name] = dataframe[name].astype('category')\n"
     ]
    }
   ],
   "source": [
    "feature_columns = []\n",
    "convert_columns(train_ds_pd, 'Transported', feature_columns)\n",
    "convert_columns(valid_ds_pd, 'Transported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8abd02b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T23:12:14.844720Z",
     "iopub.status.busy": "2023-09-05T23:12:14.843541Z",
     "iopub.status.idle": "2023-09-05T23:12:14.850336Z",
     "shell.execute_reply": "2023-09-05T23:12:14.849532Z"
    },
    "papermill": {
     "duration": 0.016723,
     "end_time": "2023-09-05T23:12:14.852100",
     "exception": false,
     "start_time": "2023-09-05T23:12:14.835377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, target=None, shuffle=True, batch_size=32):\n",
    "    df = dataframe.copy()\n",
    "    if target != None:\n",
    "        labels = df.pop(target)\n",
    "    #df = {key: value for key, value in dataframe.items()}\n",
    "    \n",
    "    if target != None:\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_tensor_slices(dict(df))\n",
    "        \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(batch_size)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4809bca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T23:12:14.868128Z",
     "iopub.status.busy": "2023-09-05T23:12:14.867476Z",
     "iopub.status.idle": "2023-09-05T23:12:15.027683Z",
     "shell.execute_reply": "2023-09-05T23:12:15.026604Z"
    },
    "papermill": {
     "duration": 0.171138,
     "end_time": "2023-09-05T23:12:15.030282",
     "exception": false,
     "start_time": "2023-09-05T23:12:14.859144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds_nn = df_to_dataset(train_ds_pd, 'Transported')\n",
    "valid_ds_nn = df_to_dataset(valid_ds_pd, 'Transported', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27cd8b2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T23:12:15.046418Z",
     "iopub.status.busy": "2023-09-05T23:12:15.045938Z",
     "iopub.status.idle": "2023-09-05T23:12:15.053231Z",
     "shell.execute_reply": "2023-09-05T23:12:15.052193Z"
    },
    "papermill": {
     "duration": 0.017459,
     "end_time": "2023-09-05T23:12:15.055302",
     "exception": false,
     "start_time": "2023-09-05T23:12:15.037843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_normalization_layer(name, dataset):\n",
    "  # Create a Normalization layer for the feature.\n",
    "  normalizer = layers.Normalization(axis=None)\n",
    "\n",
    "  # Prepare a Dataset that only yields the feature.\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the statistics of the data.\n",
    "  normalizer.adapt(feature_ds)\n",
    "\n",
    "  return normalizer\n",
    "\n",
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "  # Create a layer that turns strings into integer indices.\n",
    "  if dtype == 'string':\n",
    "    index = layers.StringLookup(max_tokens=max_tokens)\n",
    "  # Otherwise, create a layer that turns integer values into integer indices.\n",
    "  else:\n",
    "    index = layers.IntegerLookup(max_tokens=max_tokens)\n",
    "\n",
    "  # Prepare a `tf.data.Dataset` that only yields the feature.\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the set of possible values and assign them a fixed integer index.\n",
    "  index.adapt(feature_ds)\n",
    "\n",
    "  # Encode the integer indices.\n",
    "  encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "\n",
    "  # Apply multi-hot encoding to the indices. The lambda function captures the\n",
    "  # layer, so you can use them, or include them in the Keras Functional model later.\n",
    "  return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc969e59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T23:12:15.070482Z",
     "iopub.status.busy": "2023-09-05T23:12:15.070103Z",
     "iopub.status.idle": "2023-09-05T23:12:15.075048Z",
     "shell.execute_reply": "2023-09-05T23:12:15.074083Z"
    },
    "papermill": {
     "duration": 0.014685,
     "end_time": "2023-09-05T23:12:15.077020",
     "exception": false,
     "start_time": "2023-09-05T23:12:15.062335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_types = ['HomePlanet', 'Destination', 'Deck', 'Cabin_num', 'Side']\n",
    "num_types = [lab for lab in train_ds_pd.columns.values if lab not in cat_types and lab != 'Transported']\n",
    "all_inputs = []\n",
    "encoded_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27ff2b6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T23:12:15.092781Z",
     "iopub.status.busy": "2023-09-05T23:12:15.092097Z",
     "iopub.status.idle": "2023-09-05T23:12:19.121343Z",
     "shell.execute_reply": "2023-09-05T23:12:19.120211Z"
    },
    "papermill": {
     "duration": 4.040092,
     "end_time": "2023-09-05T23:12:19.123971",
     "exception": false,
     "start_time": "2023-09-05T23:12:15.083879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for header in num_types:\n",
    "    numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "    normalization_layer = get_normalization_layer(header, train_ds_nn)\n",
    "    encoded_numeric_col = normalization_layer(numeric_col)\n",
    "    all_inputs.append(numeric_col)\n",
    "    encoded_features.append(encoded_numeric_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdede939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T23:12:19.140787Z",
     "iopub.status.busy": "2023-09-05T23:12:19.140437Z",
     "iopub.status.idle": "2023-09-05T23:12:20.990682Z",
     "shell.execute_reply": "2023-09-05T23:12:20.989831Z"
    },
    "papermill": {
     "duration": 1.861158,
     "end_time": "2023-09-05T23:12:20.993129",
     "exception": false,
     "start_time": "2023-09-05T23:12:19.131971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for header in cat_types:\n",
    "    categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "    encoding_layer = get_category_encoding_layer(name=header,\n",
    "                                               dataset=train_ds_nn,\n",
    "                                               dtype='string',\n",
    "                                               max_tokens=5)\n",
    "    encoded_categorical_col = encoding_layer(categorical_col)\n",
    "    all_inputs.append(categorical_col)\n",
    "    encoded_features.append(encoded_categorical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0065e24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T23:12:21.008733Z",
     "iopub.status.busy": "2023-09-05T23:12:21.008348Z",
     "iopub.status.idle": "2023-09-05T23:12:44.277376Z",
     "shell.execute_reply": "2023-09-05T23:12:44.276447Z"
    },
    "papermill": {
     "duration": 23.279366,
     "end_time": "2023-09-05T23:12:44.279513",
     "exception": false,
     "start_time": "2023-09-05T23:12:21.000147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 2s 5ms/step - loss: 3.4230 - accuracy: 0.5494 - val_loss: 1.3143 - val_accuracy: 0.6436\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.4877 - accuracy: 0.6164 - val_loss: 1.0903 - val_accuracy: 0.7351\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.9704 - accuracy: 0.6432 - val_loss: 0.8516 - val_accuracy: 0.7427\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.6654 - accuracy: 0.6455 - val_loss: 0.6560 - val_accuracy: 0.7028\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.4494 - accuracy: 0.6505 - val_loss: 0.5701 - val_accuracy: 0.7087\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.3061 - accuracy: 0.6589 - val_loss: 0.5596 - val_accuracy: 0.7227\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1550 - accuracy: 0.6652 - val_loss: 0.5090 - val_accuracy: 0.7409\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1158 - accuracy: 0.6720 - val_loss: 0.5231 - val_accuracy: 0.7216\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1306 - accuracy: 0.6733 - val_loss: 0.5171 - val_accuracy: 0.7122\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0293 - accuracy: 0.6930 - val_loss: 0.5105 - val_accuracy: 0.7298\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9687 - accuracy: 0.6914 - val_loss: 0.4974 - val_accuracy: 0.7509\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9371 - accuracy: 0.7014 - val_loss: 0.4912 - val_accuracy: 0.7403\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9717 - accuracy: 0.6931 - val_loss: 0.5464 - val_accuracy: 0.7462\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8815 - accuracy: 0.6994 - val_loss: 0.5357 - val_accuracy: 0.7438\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8983 - accuracy: 0.6987 - val_loss: 0.5439 - val_accuracy: 0.7567\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8396 - accuracy: 0.7010 - val_loss: 0.5302 - val_accuracy: 0.7585\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8484 - accuracy: 0.7142 - val_loss: 0.5139 - val_accuracy: 0.7632\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8014 - accuracy: 0.7067 - val_loss: 0.4982 - val_accuracy: 0.7532\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.7811 - accuracy: 0.7029 - val_loss: 0.4931 - val_accuracy: 0.7573\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.7876 - accuracy: 0.7152 - val_loss: 0.4909 - val_accuracy: 0.7743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7d0178507190>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "nn_model = tf.keras.Model(all_inputs, output)\n",
    "\n",
    "nn_model.compile(optimizer='Adam',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "nn_model.fit(train_ds_nn,\n",
    "             validation_data=valid_ds_nn,\n",
    "             epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95616ca3",
   "metadata": {
    "papermill": {
     "duration": 0.022417,
     "end_time": "2023-09-05T23:12:44.324703",
     "exception": false,
     "start_time": "2023-09-05T23:12:44.302286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f9399bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T23:12:44.373152Z",
     "iopub.status.busy": "2023-09-05T23:12:44.372765Z",
     "iopub.status.idle": "2023-09-05T23:12:44.471019Z",
     "shell.execute_reply": "2023-09-05T23:12:44.469974Z"
    },
    "papermill": {
     "duration": 0.125144,
     "end_time": "2023-09-05T23:12:44.473508",
     "exception": false,
     "start_time": "2023-09-05T23:12:44.348364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')\n",
    "pid = df_test['PassengerId']\n",
    "df_test = df_test.drop(['PassengerId', 'Name'], axis=1)\n",
    "df_test[[\"Deck\", \"Cabin_num\", \"Side\"]] = df_test[\"Cabin\"].str.split(\"/\", expand=True)\n",
    "df_test = df_test.drop('Cabin', axis=1)\n",
    "df_test.fillna(0, inplace=True)\n",
    "df_test['VIP'] = df_test['VIP'].astype(int)\n",
    "df_test['CryoSleep'] = df_test['CryoSleep'].astype(int)\n",
    "df_test.head(5)\n",
    "df_test.isna().sum().sort_values(ascending=False)\n",
    "\n",
    "#for name in df_test.columns.values:\n",
    "#    if ~is_numeric_dtype(df_test[name]):\n",
    "#        df_test[name] = df_test[name].astype('category').cat.codes\n",
    "\n",
    "convert_columns(df_test)\n",
    "test_ds_nn = df_to_dataset(df_test, shuffle=False)\n",
    "#df = {key: value for key, value in df_test.items()}\n",
    "#ds = tf.data.Dataset.from_tensor_slices(dict(df))\n",
    "#test_ds_nn = tf.data.Dataset.from_tensor_slices(dict(df_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "121290dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T23:12:44.520082Z",
     "iopub.status.busy": "2023-09-05T23:12:44.519677Z",
     "iopub.status.idle": "2023-09-05T23:12:45.163409Z",
     "shell.execute_reply": "2023-09-05T23:12:45.162285Z"
    },
    "papermill": {
     "duration": 0.670145,
     "end_time": "2023-09-05T23:12:45.166030",
     "exception": false,
     "start_time": "2023-09-05T23:12:44.495885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = nn_model.predict(test_ds_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3a80c69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T23:12:45.214719Z",
     "iopub.status.busy": "2023-09-05T23:12:45.214311Z",
     "iopub.status.idle": "2023-09-05T23:12:45.221360Z",
     "shell.execute_reply": "2023-09-05T23:12:45.220366Z"
    },
    "papermill": {
     "duration": 0.033121,
     "end_time": "2023-09-05T23:12:45.223314",
     "exception": false,
     "start_time": "2023-09-05T23:12:45.190193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.6032291 ],\n",
       "       [-0.16023919],\n",
       "       [ 1.1696819 ],\n",
       "       ...,\n",
       "       [ 1.2263595 ],\n",
       "       [ 0.90142757],\n",
       "       [ 0.5297111 ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9996f8ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T23:12:45.270997Z",
     "iopub.status.busy": "2023-09-05T23:12:45.270607Z",
     "iopub.status.idle": "2023-09-05T23:12:45.283060Z",
     "shell.execute_reply": "2023-09-05T23:12:45.282159Z"
    },
    "papermill": {
     "duration": 0.039111,
     "end_time": "2023-09-05T23:12:45.285256",
     "exception": false,
     "start_time": "2023-09-05T23:12:45.246145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = [True if pred > 0 else False for pred in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f33e579c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T23:12:45.332495Z",
     "iopub.status.busy": "2023-09-05T23:12:45.332108Z",
     "iopub.status.idle": "2023-09-05T23:12:45.347680Z",
     "shell.execute_reply": "2023-09-05T23:12:45.346592Z"
    },
    "papermill": {
     "duration": 0.04181,
     "end_time": "2023-09-05T23:12:45.349922",
     "exception": false,
     "start_time": "2023-09-05T23:12:45.308112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = pd.Series(predictions, name='Transported')\n",
    "pd.concat([pid, predictions], axis=1).to_csv(\"/kaggle/working/submission.csv\", index=False)"
   ]
  }
 ],
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.6.4"
 },
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 53.569158,
   "end_time": "2023-09-05T23:12:48.271240",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-05T23:11:54.702082",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
